{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "data_root = os.path.join('.', 'notMNIST_data') # Change me to store data elsewhere\n",
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    # Load the training, validation and test data into constants that are\n",
    "    # attached to the graph.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    # These are the parameters that we are going to be training. The weight\n",
    "    # matrix will be initialized using random values following a (truncated)\n",
    "    # normal distribution. The biases get initialized to zero.\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "    # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "    # it's very common, and it can be optimized). We take the average of this\n",
    "    # cross-entropy across all training examples: that's our loss.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    # We are going to find the minimum of this loss using gradient descent.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    # These are not part of training, but merely here so that we can report\n",
    "    # accuracy figures as we train.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 18.393438\n",
      "Training accuracy: 9.6%\n",
      "Validation accuracy: 11.1%\n",
      "Loss at step 100: 2.325806\n",
      "Training accuracy: 72.2%\n",
      "Validation accuracy: 71.3%\n",
      "Loss at step 200: 1.869458\n",
      "Training accuracy: 74.8%\n",
      "Validation accuracy: 73.4%\n",
      "Loss at step 300: 1.624184\n",
      "Training accuracy: 75.9%\n",
      "Validation accuracy: 74.2%\n",
      "Loss at step 400: 1.459420\n",
      "Training accuracy: 76.7%\n",
      "Validation accuracy: 74.5%\n",
      "Loss at step 500: 1.336869\n",
      "Training accuracy: 77.5%\n",
      "Validation accuracy: 74.9%\n",
      "Loss at step 600: 1.240176\n",
      "Training accuracy: 78.3%\n",
      "Validation accuracy: 74.8%\n",
      "Loss at step 700: 1.161069\n",
      "Training accuracy: 78.9%\n",
      "Validation accuracy: 75.0%\n",
      "Loss at step 800: 1.094800\n",
      "Training accuracy: 79.4%\n",
      "Validation accuracy: 75.2%\n",
      "Test accuracy: 82.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the\n",
    "    # biases. \n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "        # and get the loss value and the training predictions returned as numpy\n",
    "        # arrays.\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(\n",
    "                predictions, train_labels[:train_subset, :]))\n",
    "            # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "            # just to get that one numpy array. Note that it recomputes all its graph\n",
    "            # dependencies.\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `session.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 14.547266\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 18.3%\n",
      "Minibatch loss at step 500: 1.367674\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 1000: 1.234886\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1500: 0.596908\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2000: 0.893151\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 2500: 1.004438\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 3000: 1.191774\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.9%\n",
      "Test accuracy: 86.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "minibatch_loss = np.zeros(num_steps)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        minibatch_loss[step] = l\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgFTeIiISMAUHiIiErD/B5plFtx/VnJJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fecbb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot smoothed loss vs. iterations\n",
    "N = 100 # smoothing\n",
    "minibatch_loss_filter = np.convolve(minibatch_loss, np.ones((N,))/N, mode='valid')\n",
    "plt.semilogy(minibatch_loss_filter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units [nn.relu()](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024;\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    \n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    a1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(a1, weights2) + biases2\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_a1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(valid_a1, weights2) + biases2)\n",
    "    test_a1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(\n",
    "        tf.matmul(test_a1, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 434.665710\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 30.0%\n",
      "Minibatch loss at step 500: 12.071770\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1000: 7.764995\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 5.900398\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2000: 3.487618\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2500: 2.360551\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 3000: 2.695564\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 89.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "minibatch_loss = np.zeros(num_steps)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        minibatch_loss[step] = l\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfub/AR8QzqKW06IsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b2e4d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100\n",
    "minibatch_loss_filter = np.convolve(minibatch_loss, np.ones((N,))/N, mode='valid')\n",
    "plt.semilogy(minibatch_loss_filter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
